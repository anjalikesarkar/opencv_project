{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a72f7e7-d82d-4422-a3b4-7651af0a8fdb",
   "metadata": {},
   "source": [
    "# SIMPLE THRESHOLDING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d232bf9d-29c9-44af-aa00-5190947bed7d",
   "metadata": {},
   "source": [
    "Is a technique used to separate the objects in an image from the background. \n",
    "It is mainly used for binary image segmentation. \n",
    "eg;Sorting fruits or vegetables based on ripeness or detecting defects,\n",
    "Lane detection and road sign recognition in self-driving cars,\n",
    "Identifying boundaries of rivers or roads in satellite images for geographical analysis,\n",
    "Security camera systems that detect motion,\n",
    "mobile apps for scanning product barcodes, and quick response codes in marketing campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658dd56-8bec-4b71-b7c8-4961a6f3bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('images//car.jpg')\n",
    "\n",
    "# Set threshold value and maxval\n",
    "thresh_value = 155\n",
    "max_value = 255\n",
    "\n",
    "_,thr = cv2.threshold(img,thresh_value,max_value,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('thresholding', thr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017acc2-afce-462a-b176-c233e07e0a4e",
   "metadata": {},
   "source": [
    "# Otsu's binary thresholding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87fa7b20-5e09-41d7-b182-42f37b5855ce",
   "metadata": {},
   "source": [
    "Is an adaptive thresholding technique used to convert a grayscale image into a binary image. \n",
    "The idea behind Otsu's method is to automatically calculate the optimal threshold value that minimizes \n",
    "the intra-class variance (the variance within the foreground and background classes) or, equivalently, \n",
    "maximizes the inter-class variance (the variance between the foreground and background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89da777-d2dc-4d9a-82b7-54bf8fb9dfbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages//smily_women.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      6\u001b[0m _,thr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(img, \u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m255\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY \u001b[38;5;241m+\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('images//smily_women.jpg')\n",
    "img = cv2.resize(img,(500,400))\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_,thr = cv2.threshold(img, 150,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Otsu Thresholding', thr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80434bc5-afa5-433a-a0e1-274cac163558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
